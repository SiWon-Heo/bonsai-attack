{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tqdm\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import MNIST, SVHN, USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 준비를 위한 transform, dataset, loader 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_set, valid_set= torch.utils.data.random_split(dataset, [40000,10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOH\n",
    "\n",
    "Dataset; CIFAR10\n",
    "\n",
    "Victim; MobileNet\n",
    "\n",
    "Shadow; SqueezeNet(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_server.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 360.8634948730469\n",
      "epoch 2: loss 355.38128662109375\n",
      "epoch 3: loss 356.6088562011719\n",
      "epoch 4: loss 354.1479187011719\n",
      "epoch 5: loss 353.891357421875\n",
      "epoch 6: loss 353.01800537109375\n",
      "epoch 7: loss 351.36688232421875\n",
      "epoch 8: loss 350.6422424316406\n",
      "epoch 9: loss 350.6971435546875\n",
      "epoch 10: loss 350.6357116699219\n",
      "epoch 11: loss 350.5658874511719\n",
      "epoch 12: loss 350.47454833984375\n",
      "epoch 13: loss 349.5735168457031\n",
      "epoch 14: loss 349.07159423828125\n",
      "epoch 15: loss 348.295654296875\n",
      "epoch 16: loss 348.69012451171875\n",
      "epoch 17: loss 348.0174865722656\n",
      "epoch 18: loss 347.276611328125\n",
      "epoch 19: loss 347.5107727050781\n",
      "epoch 20: loss 346.2996520996094\n",
      "epoch 21: loss 345.5970458984375\n",
      "epoch 22: loss 345.6961669921875\n",
      "epoch 23: loss 345.3965148925781\n",
      "epoch 24: loss 344.4766540527344\n",
      "epoch 25: loss 344.8792419433594\n",
      "epoch 26: loss 344.2704772949219\n",
      "epoch 27: loss 343.13995361328125\n",
      "epoch 28: loss 343.29827880859375\n",
      "epoch 29: loss 342.33056640625\n",
      "epoch 30: loss 341.3404541015625\n",
      "epoch 31: loss 341.6649475097656\n",
      "epoch 32: loss 340.16986083984375\n",
      "epoch 33: loss 340.0086975097656\n",
      "epoch 34: loss 339.52484130859375\n",
      "epoch 35: loss 340.0464172363281\n",
      "epoch 36: loss 340.54205322265625\n",
      "epoch 37: loss 338.7814025878906\n",
      "epoch 38: loss 338.0935363769531\n",
      "epoch 39: loss 341.211669921875\n",
      "epoch 40: loss 340.0733642578125\n",
      "epoch 41: loss 340.8737487792969\n",
      "epoch 42: loss 338.8571472167969\n",
      "epoch 43: loss 337.52117919921875\n",
      "epoch 44: loss 335.80853271484375\n",
      "epoch 45: loss 335.5854797363281\n",
      "epoch 46: loss 334.9969177246094\n",
      "epoch 47: loss 334.8643493652344\n",
      "epoch 48: loss 333.7145690917969\n",
      "epoch 49: loss 334.4315185546875\n",
      "epoch 50: loss 334.13909912109375\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "shadow_client = ClientMobileNet()\n",
    "shadow_server = ServerMobileNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/mobilenet_cifar10_c1.pth'))\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow_server.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in test_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow_server(shadow_client(x))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 5999/10000\n"
     ]
    }
   ],
   "source": [
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in train_loader:\n",
    "    y_pred = shadow_server(shadow_client(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow_server,'mobile_cifar10_partial_squeezenet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOH\n",
    "\n",
    "Dataset; CIFAR10\n",
    "\n",
    "Victim; MobileNet\n",
    "\n",
    "Shadow; SqueezeNet(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 347.5904541015625\n",
      "epoch 2: loss 332.9650573730469\n",
      "epoch 3: loss 327.3974914550781\n",
      "epoch 4: loss 323.4686584472656\n",
      "epoch 5: loss 321.5416564941406\n",
      "epoch 6: loss 318.6306457519531\n",
      "epoch 7: loss 316.3725891113281\n",
      "epoch 8: loss 313.9549560546875\n",
      "epoch 9: loss 310.8152770996094\n",
      "epoch 10: loss 309.2518310546875\n",
      "epoch 11: loss 308.26129150390625\n",
      "epoch 12: loss 306.70794677734375\n",
      "epoch 13: loss 305.8299865722656\n",
      "epoch 14: loss 305.0028381347656\n",
      "epoch 15: loss 302.9578552246094\n",
      "epoch 16: loss 301.7199401855469\n",
      "epoch 17: loss 302.11187744140625\n",
      "epoch 18: loss 300.0210266113281\n",
      "epoch 19: loss 298.55059814453125\n",
      "epoch 20: loss 298.4129333496094\n",
      "epoch 21: loss 297.7160949707031\n",
      "epoch 22: loss 299.9552307128906\n",
      "epoch 23: loss 296.4400634765625\n",
      "epoch 24: loss 295.4084167480469\n",
      "epoch 25: loss 295.0885009765625\n",
      "epoch 26: loss 295.8665771484375\n",
      "epoch 27: loss 294.68072509765625\n",
      "epoch 28: loss 294.2745666503906\n",
      "epoch 29: loss 294.9202575683594\n",
      "epoch 30: loss 294.990966796875\n",
      "epoch 31: loss 293.09857177734375\n",
      "epoch 32: loss 293.592529296875\n",
      "epoch 33: loss 293.4862976074219\n",
      "epoch 34: loss 290.9930725097656\n",
      "epoch 35: loss 290.34906005859375\n",
      "epoch 36: loss 292.3009338378906\n",
      "epoch 37: loss 289.4690856933594\n",
      "epoch 38: loss 289.94903564453125\n",
      "epoch 39: loss 288.1644287109375\n",
      "epoch 40: loss 288.6063232421875\n",
      "epoch 41: loss 287.5060119628906\n",
      "epoch 42: loss 288.0951232910156\n",
      "epoch 43: loss 286.9725646972656\n",
      "epoch 44: loss 286.3596496582031\n",
      "epoch 45: loss 285.96087646484375\n",
      "epoch 46: loss 285.67559814453125\n",
      "epoch 47: loss 287.044189453125\n",
      "epoch 48: loss 287.0418395996094\n",
      "epoch 49: loss 287.2301025390625\n",
      "epoch 50: loss 287.4949035644531\n",
      "done\n",
      "test acc : 5646/10000\n"
     ]
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_server.pth'))\n",
    "\n",
    "num_epoch = 50\n",
    "shadow_client = ClientSqueezeNet()\n",
    "shadow_server = ServerSqueezeNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow_server.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in test_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = softmax(shadow_server(shadow_client(x)))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")\n",
    "\n",
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow_server(shadow_client(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")\n",
    "\n",
    "torch.save(shadow_server,'mobile_cifar10_partial_mobilenet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOH\n",
    "\n",
    "Victim: SqueezeNet => all failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientMobilenet = ClientSqueezeNet()\n",
    "serverMobilenet = ServerSqueezeNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_server.pth'))\n",
    "\n",
    "num_epoch = 20\n",
    "shadow_client = ClientMobileNet()\n",
    "shadow_server = ServerMobileNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/mobilenet_cifar10_c0.pth'))\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow_server.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow_server(shadow_client(x))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")\n",
    "\n",
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow_server(shadow_client(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")\n",
    "\n",
    "torch.save(shadow_server,'squeeze_cifar10_partial_mobilenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 20.66016960144043\n",
      "epoch 2: loss 20.529081344604492\n",
      "epoch 3: loss 20.50014877319336\n",
      "epoch 4: loss 20.478044509887695\n",
      "epoch 5: loss 20.482629776000977\n",
      "epoch 6: loss 20.452669143676758\n",
      "epoch 7: loss 20.445524215698242\n",
      "epoch 8: loss 20.44179344177246\n",
      "epoch 9: loss 20.430282592773438\n",
      "epoch 10: loss 20.422414779663086\n",
      "epoch 11: loss 20.42481231689453\n",
      "epoch 12: loss 20.41050148010254\n",
      "epoch 13: loss 20.405685424804688\n",
      "epoch 14: loss 20.407556533813477\n",
      "epoch 15: loss 20.401308059692383\n",
      "epoch 16: loss 20.403257369995117\n",
      "epoch 17: loss 20.39028549194336\n",
      "epoch 18: loss 20.396442413330078\n",
      "epoch 19: loss 20.390295028686523\n",
      "epoch 20: loss 20.39445686340332\n",
      "done\n",
      "test acc : 1048/10000\n"
     ]
    }
   ],
   "source": [
    "clientMobilenet = ClientSqueezeNet()\n",
    "serverMobilenet = ServerSqueezeNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_server.pth'))\n",
    "\n",
    "num_epoch = 20\n",
    "shadow_client = ClientSqueezeNet()\n",
    "shadow_server = ServerSqueezeNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow_server.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow_server(shadow_client(x))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/64}\")\n",
    "print(\"done\")\n",
    "\n",
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow_server(shadow_client(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")\n",
    "\n",
    "torch.save(shadow_server,'squeeze_cifar10_partial_mobilenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 4940.9765625\n",
      "epoch 2: loss 4848.1787109375\n",
      "epoch 3: loss 4819.31982421875\n",
      "epoch 4: loss 4796.330078125\n",
      "epoch 5: loss 4797.45751953125\n",
      "epoch 6: loss 4777.63427734375\n",
      "epoch 7: loss 4785.51318359375\n",
      "epoch 8: loss 4773.89501953125\n",
      "epoch 9: loss 4770.45361328125\n",
      "epoch 10: loss 4758.4453125\n",
      "epoch 11: loss 4765.1181640625\n",
      "epoch 12: loss 4752.99658203125\n",
      "epoch 13: loss 4763.14501953125\n",
      "epoch 14: loss 4755.58056640625\n",
      "epoch 15: loss 4748.89111328125\n",
      "epoch 16: loss 4743.9208984375\n",
      "epoch 17: loss 4743.8349609375\n"
     ]
    }
   ],
   "source": [
    "clientSqueezenet = ClientSqueezeNet()\n",
    "serverSqueezenet = ServerSqueezeNet()\n",
    "clientSqueezenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "serverSqueezenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_server.pth'))\n",
    "\n",
    "num_epoch = 20\n",
    "shadow = MobileNet()\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = serverSqueezenet(clientSqueezenet(x)).detach()\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")\n",
    "\n",
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")\n",
    "\n",
    "torch.save(shadow,'squeeze_cifar10_whole_mobilenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 347.0039978027344\n",
      "epoch 2: loss 346.6831359863281\n",
      "epoch 3: loss 346.561279296875\n",
      "epoch 4: loss 346.5929260253906\n",
      "epoch 5: loss 346.7683410644531\n",
      "epoch 6: loss 346.840576171875\n",
      "epoch 7: loss 346.7769470214844\n",
      "epoch 8: loss 346.7422180175781\n",
      "epoch 9: loss 346.4700622558594\n",
      "epoch 10: loss 346.7978515625\n",
      "epoch 11: loss 346.7279357910156\n",
      "epoch 12: loss 346.5966796875\n",
      "epoch 13: loss 346.72064208984375\n",
      "epoch 14: loss 346.5398864746094\n",
      "epoch 15: loss 346.50396728515625\n",
      "epoch 16: loss 346.6377258300781\n",
      "epoch 17: loss 346.6171569824219\n",
      "epoch 18: loss 346.6437072753906\n",
      "epoch 19: loss 346.6429138183594\n",
      "epoch 20: loss 346.8576354980469\n",
      "epoch 21: loss 346.5480651855469\n",
      "epoch 22: loss 346.8531188964844\n",
      "epoch 23: loss 346.63702392578125\n",
      "epoch 24: loss 346.6578063964844\n",
      "epoch 25: loss 346.5018005371094\n",
      "epoch 26: loss 346.5928039550781\n",
      "epoch 27: loss 346.57183837890625\n",
      "epoch 28: loss 346.64581298828125\n",
      "epoch 29: loss 346.8637390136719\n",
      "epoch 30: loss 346.7839660644531\n",
      "epoch 31: loss 346.76251220703125\n",
      "epoch 32: loss 346.79852294921875\n",
      "epoch 33: loss 346.73388671875\n",
      "epoch 34: loss 346.7473449707031\n",
      "epoch 35: loss 346.91339111328125\n",
      "epoch 36: loss 346.6563415527344\n",
      "epoch 37: loss 346.5993347167969\n",
      "epoch 38: loss 346.6162414550781\n",
      "epoch 39: loss 346.5531921386719\n",
      "epoch 40: loss 346.7771911621094\n",
      "epoch 41: loss 346.67706298828125\n",
      "epoch 42: loss 346.6146240234375\n",
      "epoch 43: loss 346.4519348144531\n",
      "epoch 44: loss 346.6386413574219\n",
      "epoch 45: loss 346.66400146484375\n",
      "epoch 46: loss 346.6397705078125\n",
      "epoch 47: loss 346.6749267578125\n",
      "epoch 48: loss 346.80596923828125\n",
      "epoch 49: loss 346.8487854003906\n",
      "epoch 50: loss 346.7611389160156\n",
      "done\n",
      "test acc : 1031/10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shadow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2072652/154776434.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test acc : {acc}/{tot}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'squeeze_cifar10_whole_mobilenet.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shadow' is not defined"
     ]
    }
   ],
   "source": [
    "clientSqueezenet = ClientSqueezeNet()\n",
    "serverSqueezenet = ServerSqueezeNet()\n",
    "clientSqueezenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "serverSqueezenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_server.pth'))\n",
    "\n",
    "num_epoch = 50\n",
    "shadow_client = ClientSqueezeNet()\n",
    "shadow_server = ServerSqueezeNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow_server.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in test_loader:\n",
    "        y_label = softmax(serverSqueezenet(clientSqueezenet(x)).detach())\n",
    "        y_shadow = softmax(shadow_server(shadow_client(x)))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")\n",
    "\n",
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow_server(shadow_client(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")\n",
    "\n",
    "torch.save(shadow_server,'squeeze_cifar10_whole_mobilenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
