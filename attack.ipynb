{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 준비를 위한 transform, dataset, loader 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_set, valid_set= torch.utils.data.random_split(dataset, [40000,10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOH\n",
    "\n",
    "Dataset ; CIFAR10\n",
    "\n",
    "Victim ; MobileNet\n",
    "\n",
    "Shadow ; SqueezeNet(Untrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_server.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 344.3273010253906\n",
      "epoch 2: loss 330.463623046875\n",
      "epoch 3: loss 324.4977111816406\n",
      "epoch 4: loss 320.3070068359375\n",
      "epoch 5: loss 316.1141052246094\n",
      "epoch 6: loss 312.96038818359375\n",
      "epoch 7: loss 310.5359191894531\n",
      "epoch 8: loss 308.1898498535156\n",
      "epoch 9: loss 306.33953857421875\n",
      "epoch 10: loss 305.0871276855469\n",
      "epoch 11: loss 303.06329345703125\n",
      "epoch 12: loss 300.9832763671875\n",
      "epoch 13: loss 303.3331298828125\n",
      "epoch 14: loss 299.9398193359375\n",
      "epoch 15: loss 298.787353515625\n",
      "epoch 16: loss 295.6677551269531\n",
      "epoch 17: loss 293.6312561035156\n",
      "epoch 18: loss 291.9891052246094\n",
      "epoch 19: loss 289.7529296875\n",
      "epoch 20: loss 288.3203430175781\n",
      "epoch 21: loss 285.7350158691406\n",
      "epoch 22: loss 285.3455505371094\n",
      "epoch 23: loss 285.288818359375\n",
      "epoch 24: loss 282.95635986328125\n",
      "epoch 25: loss 280.7430725097656\n",
      "epoch 26: loss 279.1961364746094\n",
      "epoch 27: loss 277.8844299316406\n",
      "epoch 28: loss 276.6181335449219\n",
      "epoch 29: loss 276.6001281738281\n",
      "epoch 30: loss 275.6732482910156\n",
      "epoch 31: loss 277.2459411621094\n",
      "epoch 32: loss 273.2502746582031\n",
      "epoch 33: loss 273.53887939453125\n",
      "epoch 34: loss 272.8895568847656\n",
      "epoch 35: loss 272.1673278808594\n",
      "epoch 36: loss 272.7942199707031\n",
      "epoch 37: loss 271.68682861328125\n",
      "epoch 38: loss 268.6749267578125\n",
      "epoch 39: loss 268.3282775878906\n",
      "epoch 40: loss 267.85430908203125\n",
      "epoch 41: loss 266.88250732421875\n",
      "epoch 42: loss 271.1007385253906\n",
      "epoch 43: loss 269.1479187011719\n",
      "epoch 44: loss 266.2525939941406\n",
      "epoch 45: loss 264.50604248046875\n",
      "epoch 46: loss 264.34356689453125\n",
      "epoch 47: loss 265.73870849609375\n",
      "epoch 48: loss 262.97113037109375\n",
      "epoch 49: loss 263.97607421875\n",
      "epoch 50: loss 264.31036376953125\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "shadow = SqueezeNet()\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in test_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_cifar10_whole_squeezenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 5252/10000\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOH\n",
    "\n",
    "Dataset; CIFAR10\n",
    "\n",
    "Victim; MobileNet\n",
    "\n",
    "Shadow; MobileNet(Untrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 309.802978515625\n",
      "epoch 2: loss 258.3976135253906\n",
      "epoch 3: loss 226.8338623046875\n",
      "epoch 4: loss 202.29734802246094\n",
      "epoch 5: loss 186.60231018066406\n",
      "epoch 6: loss 175.2358856201172\n",
      "epoch 7: loss 162.50765991210938\n",
      "epoch 8: loss 152.2112579345703\n",
      "epoch 9: loss 144.7798614501953\n",
      "epoch 10: loss 140.2115936279297\n",
      "epoch 11: loss 135.78221130371094\n",
      "epoch 12: loss 132.74884033203125\n",
      "epoch 13: loss 130.4856414794922\n",
      "epoch 14: loss 129.74569702148438\n",
      "epoch 15: loss 126.74622344970703\n",
      "epoch 16: loss 124.76313018798828\n",
      "epoch 17: loss 123.48863220214844\n",
      "epoch 18: loss 122.2680892944336\n",
      "epoch 19: loss 122.30835723876953\n",
      "epoch 20: loss 121.899658203125\n",
      "epoch 21: loss 121.6991195678711\n",
      "epoch 22: loss 120.63117980957031\n",
      "epoch 23: loss 119.20167541503906\n",
      "epoch 24: loss 118.8907470703125\n",
      "epoch 25: loss 118.72772979736328\n",
      "epoch 26: loss 118.56607055664062\n",
      "epoch 27: loss 118.7629623413086\n",
      "epoch 28: loss 118.95840454101562\n",
      "epoch 29: loss 118.7726821899414\n",
      "epoch 30: loss 118.88065338134766\n",
      "epoch 31: loss 118.76512908935547\n",
      "epoch 32: loss 118.35022735595703\n",
      "epoch 33: loss 116.87981414794922\n",
      "epoch 34: loss 116.0427017211914\n",
      "epoch 35: loss 114.94683074951172\n",
      "epoch 36: loss 113.4801254272461\n",
      "epoch 37: loss 112.9508285522461\n",
      "epoch 38: loss 113.0673828125\n",
      "epoch 39: loss 112.24861145019531\n",
      "epoch 40: loss 112.16568756103516\n",
      "epoch 41: loss 112.33263397216797\n",
      "epoch 42: loss 112.22242736816406\n",
      "epoch 43: loss 111.9457015991211\n",
      "epoch 44: loss 112.2328109741211\n",
      "epoch 45: loss 112.80432891845703\n",
      "epoch 46: loss 112.11809539794922\n",
      "epoch 47: loss 111.9072494506836\n",
      "epoch 48: loss 112.06855773925781\n",
      "epoch 49: loss 111.95574188232422\n",
      "epoch 50: loss 111.71182250976562\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "shadow = MobileNet()\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in test_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 5851/10000\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_cifar10_whole_mobilenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_set, valid_set= torch.utils.data.random_split(dataset, [40000,10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digit5학습 모델 공격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import MNIST, SVHN, USPS\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "                                transforms.Resize((32, 32))\n",
    "                               ])\n",
    "transform_to_rgb = transforms.Compose([transforms.Grayscale(num_output_channels=3),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "                                       transforms.Resize((32, 32))\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train_usps = torchvision.datasets.USPS(root='./data' + 'usps_data', train=True, download=True, transform=transform_to_rgb)\n",
    "test_usps = torchvision.datasets.USPS(root='./data' + 'usps_data', train=False, download=True, transform=transform_to_rgb)\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(root='./data' + 'mnist_data', train=True, download=True, transform=transform_to_rgb)\n",
    "test_mnist = torchvision.datasets.MNIST(root='./data' + 'mnist_data', train=False, download=True, transform=transform_to_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_usps, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_usps, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_digit5_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_digit5_server.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-1 : Different Architecture\n",
    "Blank wholesome blackbox model\n",
    "same domain(USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 229.4803924560547\n",
      "epoch 2: loss 200.88006591796875\n",
      "epoch 3: loss 189.63145446777344\n",
      "epoch 4: loss 186.33233642578125\n",
      "epoch 5: loss 182.88233947753906\n",
      "epoch 6: loss 184.66497802734375\n",
      "epoch 7: loss 179.89984130859375\n",
      "epoch 8: loss 177.9769744873047\n",
      "epoch 9: loss 178.9838409423828\n",
      "epoch 10: loss 177.656005859375\n",
      "epoch 11: loss 177.15164184570312\n",
      "epoch 12: loss 177.6970977783203\n",
      "epoch 13: loss 178.11175537109375\n",
      "epoch 14: loss 176.59713745117188\n",
      "epoch 15: loss 177.08155822753906\n",
      "epoch 16: loss 176.92271423339844\n",
      "epoch 17: loss 175.97311401367188\n",
      "epoch 18: loss 176.08445739746094\n",
      "epoch 19: loss 176.03648376464844\n",
      "epoch 20: loss 174.8348388671875\n",
      "epoch 21: loss 174.2608642578125\n",
      "epoch 22: loss 174.98480224609375\n",
      "epoch 23: loss 174.57888793945312\n",
      "epoch 24: loss 173.9051055908203\n",
      "epoch 25: loss 173.39186096191406\n",
      "epoch 26: loss 173.59771728515625\n",
      "epoch 27: loss 173.7978057861328\n",
      "epoch 28: loss 172.5680389404297\n",
      "epoch 29: loss 172.8959197998047\n",
      "epoch 30: loss 173.48202514648438\n",
      "epoch 31: loss 173.43499755859375\n",
      "epoch 32: loss 172.96629333496094\n",
      "epoch 33: loss 172.50901794433594\n",
      "epoch 34: loss 172.31463623046875\n",
      "epoch 35: loss 172.3717803955078\n",
      "epoch 36: loss 171.4944305419922\n",
      "epoch 37: loss 170.77671813964844\n",
      "epoch 38: loss 172.14747619628906\n",
      "epoch 39: loss 171.94651794433594\n",
      "epoch 40: loss 170.8857421875\n",
      "epoch 41: loss 170.52862548828125\n",
      "epoch 42: loss 170.34034729003906\n",
      "epoch 43: loss 170.160888671875\n",
      "epoch 44: loss 170.66505432128906\n",
      "epoch 45: loss 170.3856658935547\n",
      "epoch 46: loss 170.35601806640625\n",
      "epoch 47: loss 171.4737548828125\n",
      "epoch 48: loss 173.38580322265625\n",
      "epoch 49: loss 173.47286987304688\n",
      "epoch 50: loss 171.4092559814453\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "shadow = SqueezeNet(num_classes=10)\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 799/2007\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_usps_whole_squeezenet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 8000\n",
    "indices = range(8000,16000)\n",
    "mnist_train_loader = torch.utils.data.DataLoader(Subset(train_mnist, indices), batch_size=64, shuffle=False)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target: Mobilenet-Digit5\n",
    "Attacker : Squeezenet MNIST(same dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 22.8120174407959\n",
      "epoch 2: loss 21.09133529663086\n",
      "epoch 3: loss 20.828954696655273\n",
      "epoch 4: loss 20.78696632385254\n",
      "epoch 5: loss 20.70159339904785\n",
      "epoch 6: loss 20.680931091308594\n",
      "epoch 7: loss 20.603588104248047\n",
      "epoch 8: loss 20.59605598449707\n",
      "epoch 9: loss 20.589523315429688\n",
      "epoch 10: loss 20.557926177978516\n",
      "epoch 11: loss 20.57498550415039\n",
      "epoch 12: loss 20.540122985839844\n",
      "epoch 13: loss 20.55400848388672\n",
      "epoch 14: loss 20.476640701293945\n",
      "epoch 15: loss 20.494062423706055\n",
      "epoch 16: loss 20.47201156616211\n",
      "epoch 17: loss 20.410049438476562\n",
      "epoch 18: loss 20.42901039123535\n",
      "epoch 19: loss 20.39900779724121\n",
      "epoch 20: loss 20.35149383544922\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "shadow = SqueezeNet(num_classes=10)\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in mnist_train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 5044/10000\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_mnist_whole_squeezenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_usps, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_usps, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-2 : Different Architecture\n",
    "Blank wholesome blackbox model\n",
    "different domain(Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 261.7731018066406\n",
      "epoch 2: loss 261.4520263671875\n",
      "epoch 3: loss 261.480224609375\n",
      "epoch 4: loss 261.5951843261719\n",
      "epoch 5: loss 261.60589599609375\n",
      "epoch 6: loss 261.54962158203125\n",
      "epoch 7: loss 261.5716247558594\n",
      "epoch 8: loss 261.5108642578125\n",
      "epoch 9: loss 261.626708984375\n",
      "epoch 10: loss 261.5336608886719\n",
      "epoch 11: loss 261.6938171386719\n",
      "epoch 12: loss 261.50103759765625\n",
      "epoch 13: loss 261.59173583984375\n",
      "epoch 14: loss 261.42791748046875\n",
      "epoch 15: loss 261.4223327636719\n",
      "epoch 16: loss 261.43798828125\n",
      "epoch 17: loss 261.34271240234375\n",
      "epoch 18: loss 261.3768005371094\n",
      "epoch 19: loss 261.6382751464844\n",
      "epoch 20: loss 261.51336669921875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "shadow = SqueezeNet(num_classes=10)\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        x = torch.randn_like(x)\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 198/2007\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_usps_whole_squeezenet_noise.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_digit5_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_digit5_server.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-3 : Same Architecture\n",
    "Blank wholesome blackbox model\n",
    "same domain(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 8000\n",
    "indices = range(8000,16000)\n",
    "mnist_train_loader = torch.utils.data.DataLoader(Subset(train_mnist, indices), batch_size=64, shuffle=False)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 1.824452519416809\n",
      "epoch 2: loss 0.5201795697212219\n",
      "epoch 3: loss 0.27422887086868286\n",
      "epoch 4: loss 0.2657982110977173\n",
      "epoch 5: loss 0.23205013573169708\n",
      "epoch 6: loss 0.22181165218353271\n",
      "epoch 7: loss 0.20782308280467987\n",
      "epoch 8: loss 0.19835729897022247\n",
      "epoch 9: loss 0.18525664508342743\n",
      "epoch 10: loss 0.1815684586763382\n",
      "epoch 11: loss 0.17734026908874512\n",
      "epoch 12: loss 0.17177267372608185\n",
      "epoch 13: loss 0.17308466136455536\n",
      "epoch 14: loss 0.1702556163072586\n",
      "epoch 15: loss 0.1667814701795578\n",
      "epoch 16: loss 0.1675107628107071\n",
      "epoch 17: loss 0.15633940696716309\n",
      "epoch 18: loss 0.15821707248687744\n",
      "epoch 19: loss 0.15416815876960754\n",
      "epoch 20: loss 0.16101135313510895\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "shadow = MobileNet()\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in mnist_train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 9721/10000\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_mnist_whole_mobile.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-3 : Same Architecture\n",
    "Blank wholesome blackbox model\n",
    "same domain(USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 2.040894031524658\n",
      "epoch 2: loss 1.0008713006973267\n",
      "epoch 3: loss 0.7710716724395752\n",
      "epoch 4: loss 0.6812163591384888\n",
      "epoch 5: loss 0.6324265003204346\n",
      "epoch 6: loss 0.5934742093086243\n",
      "epoch 7: loss 0.5745225548744202\n",
      "epoch 8: loss 0.5666912198066711\n",
      "epoch 9: loss 0.5416908860206604\n",
      "epoch 10: loss 0.5468255877494812\n",
      "epoch 11: loss 0.5244064927101135\n",
      "epoch 12: loss 0.5182403922080994\n",
      "epoch 13: loss 0.5096077919006348\n",
      "epoch 14: loss 0.5216582417488098\n",
      "epoch 15: loss 0.49690723419189453\n",
      "epoch 16: loss 0.49417728185653687\n",
      "epoch 17: loss 0.4856204688549042\n",
      "epoch 18: loss 0.48820456862449646\n",
      "epoch 19: loss 0.47295477986335754\n",
      "epoch 20: loss 0.46843668818473816\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "shadow = MobileNet()\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 1781/2007\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_usps_whole_mobilenet_noise_ep20.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-1 : Same Architecture\n",
    "Blank wholesome blackbox model\n",
    "Different domain(Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 22.642337799072266\n",
      "epoch 2: loss 22.539932250976562\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 2\n",
    "shadow = MobileNet()\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        x = torch.randn_like(x)\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise는 학습 불가한것으로 결론.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-1 : Same Architecture\n",
    "Partial blackbox model. same front attached\n",
    "same domain(usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_front = ClientMobileNet()\n",
    "shadow_front.load_state_dict(torch.load('./assets/mobilenet_digit5_c0.pth'))\n",
    "shadow = ServerMobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 3.4655168056488037\n",
      "epoch 2: loss 3.0560548305511475\n",
      "epoch 3: loss 2.9641506671905518\n",
      "epoch 4: loss 2.9444713592529297\n",
      "epoch 5: loss 2.907142162322998\n",
      "epoch 6: loss 2.8728983402252197\n",
      "epoch 7: loss 2.8702809810638428\n",
      "epoch 8: loss 2.8783111572265625\n",
      "epoch 9: loss 2.8668599128723145\n",
      "epoch 10: loss 2.8537611961364746\n",
      "epoch 11: loss 2.851823091506958\n",
      "epoch 12: loss 2.868387460708618\n",
      "epoch 13: loss 2.8465332984924316\n",
      "epoch 14: loss 2.8660573959350586\n",
      "epoch 15: loss 2.8559341430664062\n",
      "epoch 16: loss 2.833228349685669\n",
      "epoch 17: loss 2.840780019760132\n",
      "epoch 18: loss 2.8572661876678467\n",
      "epoch 19: loss 2.838947057723999\n",
      "epoch 20: loss 2.8413050174713135\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = softmax(shadow(shadow_front(x)))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 1788/2007\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(shadow_front(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-1 : Same Architecture\n",
    "Partial blackbox model. Different front attached\n",
    "Different domain(usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_front = ClientMobileNet()\n",
    "shadow_front.load_state_dict(torch.load('./assets/mobilenet_digit5_c1.pth'))\n",
    "shadow = ServerMobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 3.4753286838531494\n",
      "epoch 2: loss 3.1104323863983154\n",
      "epoch 3: loss 3.007295846939087\n",
      "epoch 4: loss 2.9293928146362305\n",
      "epoch 5: loss 2.88307785987854\n",
      "epoch 6: loss 2.8843109607696533\n",
      "epoch 7: loss 2.8699681758880615\n",
      "epoch 8: loss 2.8695759773254395\n",
      "epoch 9: loss 2.866029739379883\n",
      "epoch 10: loss 2.8651697635650635\n",
      "epoch 11: loss 2.8453316688537598\n",
      "epoch 12: loss 2.852083206176758\n",
      "epoch 13: loss 2.868345022201538\n",
      "epoch 14: loss 2.8736839294433594\n",
      "epoch 15: loss 2.834691047668457\n",
      "epoch 16: loss 2.855942487716675\n",
      "epoch 17: loss 2.8589773178100586\n",
      "epoch 18: loss 2.842564821243286\n",
      "epoch 19: loss 2.839914321899414\n",
      "epoch 20: loss 2.8349411487579346\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = softmax(shadow(shadow_front(x)))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 1806/2007\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(shadow_front(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_usps_partial_mobilenet_ep20.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target2-1 : Same Architecture\n",
    "Partial blackbox model. Different front attached(c1)\n",
    "same domain(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_front = ClientMobileNet()\n",
    "shadow_front.load_state_dict(torch.load('./assets/mobilenet_digit5_c1.pth'))\n",
    "shadow = ServerMobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 8000\n",
    "indices = range(8000,16000)\n",
    "mnist_train_loader = torch.utils.data.DataLoader(Subset(train_mnist, indices), batch_size=64, shuffle=False)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 3.746610641479492\n",
      "epoch 2: loss 3.2019877433776855\n",
      "epoch 3: loss 3.0356059074401855\n",
      "epoch 4: loss 2.988276720046997\n",
      "epoch 5: loss 2.9874203205108643\n",
      "epoch 6: loss 2.957688808441162\n",
      "epoch 7: loss 2.9688665866851807\n",
      "epoch 8: loss 2.9690699577331543\n",
      "epoch 9: loss 2.940988540649414\n",
      "epoch 10: loss 2.9425668716430664\n",
      "epoch 11: loss 2.939539670944214\n",
      "epoch 12: loss 2.9411840438842773\n",
      "epoch 13: loss 2.95296573638916\n",
      "epoch 14: loss 2.9514353275299072\n",
      "epoch 15: loss 2.949476957321167\n",
      "epoch 16: loss 2.9341206550598145\n",
      "epoch 17: loss 2.941539764404297\n",
      "epoch 18: loss 2.9480156898498535\n",
      "epoch 19: loss 2.9300954341888428\n",
      "epoch 20: loss 2.931401014328003\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "optimizer = optim.Adam(shadow.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow.train()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in mnist_train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = softmax(shadow(shadow_front(x)))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 9528/10000\n"
     ]
    }
   ],
   "source": [
    "shadow.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow(shadow_front(x))\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow,'mobile_mnist_c1_partial_mobilenet_ep20.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOH\n",
    "\n",
    "Dataset; CIFAR10\n",
    "\n",
    "Target; MobileNet\n",
    "\n",
    "Shadow; Mobile Front(pretrained) + SqueezeNet back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data',train=False, download=True, transform=transform)\n",
    "train_set, valid_set= torch.utils.data.random_split(dataset, [40000,10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_c0.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_cifar10_server.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_client = ClientMobileNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/mobilenet_cifar10_c0.pth'))\n",
    "shadow_server = ShadowSqueezeNet()\n",
    "mobile_squeeze = shadow_server.load_front_model(shadow_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1: loss 5.235965251922607\n",
      "epoch 2: loss 4.825255393981934\n",
      "epoch 3: loss 4.582886695861816\n",
      "epoch 4: loss 4.393383979797363\n",
      "epoch 5: loss 4.286125183105469\n",
      "epoch 6: loss 4.16935920715332\n",
      "epoch 7: loss 4.129035949707031\n",
      "epoch 8: loss 4.025527000427246\n",
      "epoch 9: loss 3.9936635494232178\n",
      "epoch 10: loss 3.8933160305023193\n",
      "epoch 11: loss 3.817272424697876\n",
      "epoch 12: loss 3.7791669368743896\n",
      "epoch 13: loss 3.7239251136779785\n",
      "epoch 14: loss 3.6836495399475098\n",
      "epoch 15: loss 3.6379024982452393\n",
      "epoch 16: loss 3.6065304279327393\n",
      "epoch 17: loss 3.583343267440796\n",
      "epoch 18: loss 3.571096658706665\n",
      "epoch 19: loss 3.5324909687042236\n",
      "epoch 20: loss 3.4845147132873535\n",
      "epoch 21: loss 3.506573438644409\n",
      "epoch 22: loss 3.491093158721924\n",
      "epoch 23: loss 3.4377591609954834\n",
      "epoch 24: loss 3.4294557571411133\n",
      "epoch 25: loss 3.3747241497039795\n",
      "epoch 26: loss 3.371398687362671\n",
      "epoch 27: loss 3.360705614089966\n",
      "epoch 28: loss 3.4029669761657715\n",
      "epoch 29: loss 3.3610198497772217\n",
      "epoch 30: loss 3.3191468715667725\n",
      "epoch 31: loss 3.2750866413116455\n",
      "epoch 32: loss 3.2570526599884033\n",
      "epoch 33: loss 3.262763738632202\n",
      "epoch 34: loss 3.258336067199707\n",
      "epoch 35: loss 3.238891363143921\n",
      "epoch 36: loss 3.1970696449279785\n",
      "epoch 37: loss 3.1702635288238525\n",
      "epoch 38: loss 3.1713149547576904\n",
      "epoch 39: loss 3.182809829711914\n",
      "epoch 40: loss 3.157179594039917\n",
      "epoch 41: loss 3.175847053527832\n",
      "epoch 42: loss 3.1633965969085693\n",
      "epoch 43: loss 3.1550793647766113\n",
      "epoch 44: loss 3.1151604652404785\n",
      "epoch 45: loss 3.098590850830078\n",
      "epoch 46: loss 3.0781569480895996\n",
      "epoch 47: loss 3.058135747909546\n",
      "epoch 48: loss 3.0651986598968506\n",
      "epoch 49: loss 3.0300629138946533\n",
      "epoch 50: loss 3.001567840576172\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow_server.train()\n",
    "print(1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in test_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow_server(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 5433/10000\n"
     ]
    }
   ],
   "source": [
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in valid_loader:\n",
    "    y_pred = shadow_server(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow_server, './mobile_squeeze_cifar10_co.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientSqueezenet = ClientSqueezeNet()\n",
    "serverSqueezenet = ServerSqueezeNet()\n",
    "clientSqueezenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "serverSqueezenet.load_state_dict(torch.load('./assets/squeezenet_cifar10_server.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_client = ClientSqueezeNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/squeezenet_cifar10_c0.pth'))\n",
    "shadow_server = ShadowMobileNet()\n",
    "squeeze_mobile = shadow_server.load_front_model(shadow_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1: loss 20.908632278442383\n",
      "epoch 2: loss 20.52694320678711\n",
      "epoch 3: loss 20.442623138427734\n",
      "epoch 4: loss 20.389854431152344\n",
      "epoch 5: loss 20.37710189819336\n",
      "epoch 6: loss 20.339073181152344\n",
      "epoch 7: loss 20.351835250854492\n",
      "epoch 8: loss 20.36783218383789\n",
      "epoch 9: loss 20.342254638671875\n",
      "epoch 10: loss 20.435396194458008\n",
      "epoch 11: loss 20.41314697265625\n",
      "epoch 12: loss 20.415699005126953\n",
      "epoch 13: loss 20.373031616210938\n",
      "epoch 14: loss 20.408363342285156\n",
      "epoch 15: loss 20.396995544433594\n",
      "epoch 16: loss 20.40045166015625\n",
      "epoch 17: loss 20.35091781616211\n",
      "epoch 18: loss 20.341148376464844\n",
      "epoch 19: loss 20.358705520629883\n",
      "epoch 20: loss 20.429418563842773\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow_server.train()\n",
    "print(1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        y_label = softmax(serverSqueezenet(clientSqueezenet(x)).detach())\n",
    "        y_shadow = shadow_server(x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 1021/10000\n"
     ]
    }
   ],
   "source": [
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in test_loader:\n",
    "    y_pred = shadow_server(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientMobilenet = ClientMobileNet()\n",
    "serverMobilenet = ServerMobileNet()\n",
    "clientMobilenet.load_state_dict(torch.load('./assets/mobilenet_digit5_c1.pth'))\n",
    "serverMobilenet.load_state_dict(torch.load('./assets/mobilenet_digit5_server.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_client = ClientMobileNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/mobilenet_digit5_c1.pth'))\n",
    "shadow_server = ShadowSqueezeNet()\n",
    "mobile_squeeze = shadow_server.load_front_model(shadow_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 8000\n",
    "indices = range(8000,16000)\n",
    "mnist_train_loader = torch.utils.data.DataLoader(Subset(train_mnist, indices), batch_size=64, shuffle=False)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=False)\n",
    "\n",
    "train_usps = torchvision.datasets.USPS(root='./data' + 'usps_data', train=True, download=True, transform=transform_to_rgb)\n",
    "test_usps = torchvision.datasets.USPS(root='./data' + 'usps_data', train=False, download=True, transform=transform_to_rgb)\n",
    "\n",
    "usps_train_loader = torch.utils.data.DataLoader(train_usps, batch_size=64, shuffle=False)\n",
    "usps_test_loader = torch.utils.data.DataLoader(test_usps, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1: loss 3.7576987743377686\n",
      "epoch 2: loss 2.9482035636901855\n",
      "epoch 3: loss 2.3557634353637695\n",
      "epoch 4: loss 1.916349172592163\n",
      "epoch 5: loss 1.7304333448410034\n",
      "epoch 6: loss 1.6401710510253906\n",
      "epoch 7: loss 1.5729318857192993\n",
      "epoch 8: loss 1.5377154350280762\n",
      "epoch 9: loss 1.5021400451660156\n",
      "epoch 10: loss 1.5350316762924194\n",
      "epoch 11: loss 1.5034326314926147\n",
      "epoch 12: loss 1.4694615602493286\n",
      "epoch 13: loss 1.4624309539794922\n",
      "epoch 14: loss 1.449779748916626\n",
      "epoch 15: loss 1.4303733110427856\n",
      "epoch 16: loss 1.4309992790222168\n",
      "epoch 17: loss 1.3858239650726318\n",
      "epoch 18: loss 1.3820680379867554\n",
      "epoch 19: loss 1.3882529735565186\n",
      "epoch 20: loss 1.346755027770996\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow_server.train()\n",
    "print(1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in usps_train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow_server(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 1522/2007\n"
     ]
    }
   ],
   "source": [
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in usps_test_loader:\n",
    "    y_pred = shadow_server(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow_server, './mobile_squeeze_usps_co.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1: loss 4.313322067260742\n",
      "epoch 2: loss 3.7973196506500244\n",
      "epoch 3: loss 3.6821656227111816\n",
      "epoch 4: loss 3.6508772373199463\n",
      "epoch 5: loss 3.647822618484497\n",
      "epoch 6: loss 3.6435370445251465\n",
      "epoch 7: loss 3.6251089572906494\n",
      "epoch 8: loss 3.6206424236297607\n",
      "epoch 9: loss 3.6111395359039307\n",
      "epoch 10: loss 3.612455368041992\n",
      "epoch 11: loss 3.6165082454681396\n",
      "epoch 12: loss 3.609854221343994\n",
      "epoch 13: loss 3.6116552352905273\n",
      "epoch 14: loss 3.6160542964935303\n",
      "epoch 15: loss 3.6021130084991455\n",
      "epoch 16: loss 3.7416164875030518\n",
      "epoch 17: loss 3.633845090866089\n",
      "epoch 18: loss 3.636012315750122\n",
      "epoch 19: loss 3.6149606704711914\n",
      "epoch 20: loss 3.6080105304718018\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "shadow_client = ClientMobileNet()\n",
    "shadow_client.load_state_dict(torch.load('./assets/mobilenet_digit5_c1.pth'))\n",
    "shadow_server = ShadowSqueezeNet()\n",
    "mobile_squeeze = shadow_server.load_front_model(shadow_client)\n",
    "\n",
    "num_epoch = 20\n",
    "optimizer = optim.Adam(shadow_server.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "batch=64\n",
    "shadow_server.train()\n",
    "print(1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for x,y in mnist_train_loader:\n",
    "        y_label = softmax(serverMobilenet(clientMobilenet(x)).detach())\n",
    "        y_shadow = shadow_server(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_shadow, y_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {(epoch+1)}: loss {total_loss/batch}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_server.eval()\n",
    "acc, tot = 0, 0\n",
    "for x, y in mnist_valid_loader:\n",
    "    y_pred = shadow_server(x)\n",
    "    acc += (y==y_pred.argmax(1)).sum()\n",
    "    tot += len(y)\n",
    "print(f\"test acc : {acc}/{tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow_server, './mobile_squeeze_mnist_co.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
